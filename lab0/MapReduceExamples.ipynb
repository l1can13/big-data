{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82OvPKEiEqjc"
   },
   "source": [
    "# Введение в MapReduce модель на Python\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JQ2cvXLjICmI",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.697422200Z",
     "start_time": "2024-04-08T14:20:38.484061700Z"
    }
   },
   "source": [
    "from typing import NamedTuple # requires python 3.6+\n",
    "from typing import Iterator"
   ],
   "execution_count": 212,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yjPHumVwEyEg",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.857426400Z",
     "start_time": "2024-04-08T14:20:38.502079600Z"
    }
   },
   "source": [
    "def MAP(_, row:NamedTuple):\n",
    "  if (row.gender == 'female'):\n",
    "    yield (row.age, row)\n",
    "    \n",
    "def REDUCE(age:str, rows:Iterator[NamedTuple]):\n",
    "  sum = 0\n",
    "  count = 0\n",
    "  for row in rows:\n",
    "    sum += row.social_contacts\n",
    "    count += 1\n",
    "  if (count > 0):\n",
    "    yield (age, sum/count)\n",
    "  else:\n",
    "    yield (age, 0)"
   ],
   "execution_count": 213,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBKMgpG_ilaZ"
   },
   "source": [
    "Модель элемента данных"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Rv-XIjhTJPx3",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.867440200Z",
     "start_time": "2024-04-08T14:20:38.564617400Z"
    }
   },
   "source": [
    "class User(NamedTuple):\n",
    "  id: int\n",
    "  age: str\n",
    "  social_contacts: int\n",
    "  gender: str"
   ],
   "execution_count": 214,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5KV0Ze2vQgu5",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.880461700Z",
     "start_time": "2024-04-08T14:20:38.580632Z"
    }
   },
   "source": [
    "input_collection = [\n",
    "    User(id=0, age=55, gender='male', social_contacts=20),\n",
    "    User(id=1, age=25, gender='female', social_contacts=240),\n",
    "    User(id=2, age=25, gender='female', social_contacts=500),\n",
    "    User(id=3, age=33, gender='female', social_contacts=800)\n",
    "]"
   ],
   "execution_count": 215,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFeqzyZxZIFZ"
   },
   "source": [
    "Функция RECORDREADER моделирует чтение элементов с диска или по сети."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S5HR4E_GQoMJ",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.890964700Z",
     "start_time": "2024-04-08T14:20:38.597143700Z"
    }
   },
   "source": [
    "def RECORDREADER():\n",
    "  return [(u.id, u) for u in input_collection]"
   ],
   "execution_count": 216,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NeEoWla-ROUy",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "outputId": "94ca6e0e-4644-4282-acbf-1759d7ba2918",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.938016300Z",
     "start_time": "2024-04-08T14:20:38.612167300Z"
    }
   },
   "source": [
    "list(RECORDREADER())"
   ],
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0, User(id=0, age=55, social_contacts=20, gender='male')),\n (1, User(id=1, age=25, social_contacts=240, gender='female')),\n (2, User(id=2, age=25, social_contacts=500, gender='female')),\n (3, User(id=3, age=33, social_contacts=800, gender='female'))]"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YB8orgPSZs8M",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.938016300Z",
     "start_time": "2024-04-08T14:20:38.674407500Z"
    }
   },
   "source": [
    "def flatten(nested_iterable):\n",
    "  for iterable in nested_iterable:\n",
    "    for element in iterable:\n",
    "      yield element"
   ],
   "execution_count": 218,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "74oyvDLaRmd5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "outputId": "c6147702-7153-47c7-a574-d5fe6abe29a8",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.939520400Z",
     "start_time": "2024-04-08T14:20:38.690424300Z"
    }
   },
   "source": [
    "map_output = flatten(map(lambda x: MAP(*x), RECORDREADER()))\n",
    "map_output = list(map_output) # materialize\n",
    "map_output"
   ],
   "execution_count": 219,
   "outputs": [
    {
     "data": {
      "text/plain": "[(25, User(id=1, age=25, social_contacts=240, gender='female')),\n (25, User(id=2, age=25, social_contacts=500, gender='female')),\n (33, User(id=3, age=33, social_contacts=800, gender='female'))]"
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8ncYDJ3-VzDn",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.939520400Z",
     "start_time": "2024-04-08T14:20:38.705932100Z"
    }
   },
   "source": [
    "def groupbykey(iterable):\n",
    "  t = {}\n",
    "  for (k2, v2) in iterable:\n",
    "    t[k2] = t.get(k2, []) + [v2]\n",
    "  return t.items()"
   ],
   "execution_count": 220,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cKzY_6COWOA2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "outputId": "e6791b12-e409-47e9-bcd4-e9f8ca8611bd",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.939520400Z",
     "start_time": "2024-04-08T14:20:38.721608500Z"
    }
   },
   "source": [
    "shuffle_output = groupbykey(map_output)\n",
    "shuffle_output = list(shuffle_output)\n",
    "shuffle_output"
   ],
   "execution_count": 221,
   "outputs": [
    {
     "data": {
      "text/plain": "[(25,\n  [User(id=1, age=25, social_contacts=240, gender='female'),\n   User(id=2, age=25, social_contacts=500, gender='female')]),\n (33, [User(id=3, age=33, social_contacts=800, gender='female')])]"
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NlA7lkDDYL0t",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "6b25d03f-5c92-4f3b-f500-6d70acd598b7",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.940524900Z",
     "start_time": "2024-04-08T14:20:38.737125400Z"
    }
   },
   "source": [
    "reduce_output = flatten(map(lambda x: REDUCE(*x), shuffle_output))\n",
    "reduce_output = list(reduce_output)\n",
    "reduce_output"
   ],
   "execution_count": 222,
   "outputs": [
    {
     "data": {
      "text/plain": "[(25, 370.0), (33, 800.0)]"
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xf6qhHEtd6bI"
   },
   "source": [
    "Все действия одним конвейером!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dZaQGYxCdpw5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "3f5c6425-e5c5-49d2-b2cd-ce58a9acc33c",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.940524900Z",
     "start_time": "2024-04-08T14:20:38.753147400Z"
    }
   },
   "source": [
    "list(flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER()))))))"
   ],
   "execution_count": 223,
   "outputs": [
    {
     "data": {
      "text/plain": "[(25, 370.0), (33, 800.0)]"
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vq3EWRIpwSiJ"
   },
   "source": [
    "# **MapReduce**\n",
    "Выделим общую для всех пользователей часть системы в отдельную функцию высшего порядка. Это наиболее простая модель MapReduce, без учёта распределённого хранения данных. \n",
    "\n",
    "Пользователь для решения своей задачи реализует RECORDREADER, MAP, REDUCE."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V1PZeQMwwVjc",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.940524900Z",
     "start_time": "2024-04-08T14:20:38.818389700Z"
    }
   },
   "source": [
    "def flatten(nested_iterable):\n",
    "  for iterable in nested_iterable:\n",
    "    for element in iterable:\n",
    "      yield element\n",
    "\n",
    "def groupbykey(iterable):\n",
    "  t = {}\n",
    "  for (k2, v2) in iterable:\n",
    "    t[k2] = t.get(k2, []) + [v2]\n",
    "  return t.items()\n",
    "\n",
    "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
    "  return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER())))))"
   ],
   "execution_count": 224,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFIVrimep678"
   },
   "source": [
    "## Спецификация MapReduce\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "f (k1, v1) -> (k2,v2)*\n",
    "g (k2, v2*) -> (k3,v3)*\n",
    " \n",
    "mapreduce ((k1,v1)*) -> (k3,v3)*\n",
    "groupby ((k2,v2)*) -> (k2,v2*)*\n",
    "flatten (e2**) -> e2*\n",
    " \n",
    "mapreduce .map(f).flatten.groupby(k2).map(g).flatten\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtTFyqke3KGe"
   },
   "source": [
    "# Примеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNhh5763w5Vn"
   },
   "source": [
    "## SQL "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QkyurnvGxBGk",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "84761282-d2ba-435a-e8d7-a85150730e10",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.940524900Z",
     "start_time": "2024-04-08T14:20:38.838408500Z"
    }
   },
   "source": [
    "from typing import NamedTuple # requires python 3.6+\n",
    "from typing import Iterator\n",
    "\n",
    "class User(NamedTuple):\n",
    "  id: int\n",
    "  age: str\n",
    "  social_contacts: int\n",
    "  gender: str\n",
    "    \n",
    "input_collection = [\n",
    "    User(id=0, age=55, gender='male', social_contacts=20),\n",
    "    User(id=1, age=25, gender='female', social_contacts=240),\n",
    "    User(id=2, age=25, gender='female', social_contacts=500),\n",
    "    User(id=3, age=33, gender='female', social_contacts=800)\n",
    "]\n",
    "\n",
    "def MAP(_, row:NamedTuple):\n",
    "  if (row.gender == 'female'):\n",
    "    yield (row.age, row)\n",
    "    \n",
    "def REDUCE(age:str, rows:Iterator[NamedTuple]):\n",
    "  sum = 0\n",
    "  count = 0\n",
    "  for row in rows:\n",
    "    sum += row.social_contacts\n",
    "    count += 1\n",
    "  if (count > 0):\n",
    "    yield (age, sum/count)\n",
    "  else:\n",
    "    yield (age, 0)\n",
    " \n",
    "def RECORDREADER():\n",
    "  return [(u.id, u) for u in input_collection]\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "output = list(output)\n",
    "output"
   ],
   "execution_count": 225,
   "outputs": [
    {
     "data": {
      "text/plain": "[(25, 370.0), (33, 800.0)]"
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNKYIeerx0nY"
   },
   "source": [
    "## Matrix-Vector multiplication "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rwcntRcCyi1V",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "outputId": "606737ab-6b55-455c-931f-4fc45155f8a9",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:38.941526100Z",
     "start_time": "2024-04-08T14:20:38.851427100Z"
    }
   },
   "source": [
    "from typing import Iterator\n",
    "import numpy as np\n",
    "\n",
    "mat = np.ones((5,4))\n",
    "vec = np.random.rand(4) # in-memory vector in all map tasks\n",
    "\n",
    "def MAP(coordinates:(int, int), value:int):\n",
    "  i, j = coordinates\n",
    "  yield (i, value*vec[j])\n",
    " \n",
    "def REDUCE(i:int, products:Iterator[NamedTuple]):\n",
    "  sum = 0\n",
    "  for p in products:\n",
    "    sum += p\n",
    "  yield (i, sum)\n",
    "\n",
    "def RECORDREADER():\n",
    "  for i in range(mat.shape[0]):\n",
    "    for j in range(mat.shape[1]):\n",
    "      yield ((i, j), mat[i,j])\n",
    "      \n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "output = list(output)\n",
    "output"
   ],
   "execution_count": 226,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0, 1.2041677803627377),\n (1, 1.2041677803627377),\n (2, 1.2041677803627377),\n (3, 1.2041677803627377),\n (4, 1.2041677803627377)]"
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruZREYdi2o4O"
   },
   "source": [
    "## Inverted index "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vt9H9Alf3TYv",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "outputId": "51aeffc9-e111-4607-bd84-cfcc7b56f238",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.037195500Z",
     "start_time": "2024-04-08T14:20:38.867440200Z"
    }
   },
   "source": [
    "from typing import Iterator\n",
    "\n",
    "d1 = \"it is what it is\"\n",
    "d2 = \"what is it\"\n",
    "d3 = \"it is a banana\"\n",
    "documents = [d1, d2, d3]\n",
    "\n",
    "def RECORDREADER():\n",
    "  for (docid, document) in enumerate(documents):\n",
    "    yield (\"{}\".format(docid), document)\n",
    "      \n",
    "def MAP(docId:str, body:str):\n",
    "  for word in set(body.split(' ')):\n",
    "    yield (word, docId)\n",
    " \n",
    "def REDUCE(word:str, docIds:Iterator[str]):\n",
    "  yield (word, sorted(docIds))\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "output = list(output)\n",
    "output"
   ],
   "execution_count": 227,
   "outputs": [
    {
     "data": {
      "text/plain": "[('is', ['0', '1', '2']),\n ('it', ['0', '1', '2']),\n ('what', ['0', '1']),\n ('banana', ['2']),\n ('a', ['2'])]"
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7az-6DA6qr2"
   },
   "source": [
    "## WordCount"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dN-nbtgG6uYG",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "24117576-7931-401d-a581-28e246b23453",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.050210Z",
     "start_time": "2024-04-08T14:20:38.883460700Z"
    }
   },
   "source": [
    "from typing import Iterator\n",
    "\n",
    "d1 = \"\"\"\n",
    "it is what it is\n",
    "it is what it is\n",
    "it is what it is\"\"\"\n",
    "d2 = \"\"\"\n",
    "what is it\n",
    "what is it\"\"\"\n",
    "d3 = \"\"\"\n",
    "it is a banana\"\"\"\n",
    "documents = [d1, d2, d3]\n",
    "\n",
    "def RECORDREADER():\n",
    "  for (docid, document) in enumerate(documents):\n",
    "    for (lineid, line) in enumerate(document.split('\\n')):\n",
    "      yield (\"{}:{}\".format(docid,lineid), line)\n",
    "\n",
    "def MAP(docId:str, line:str):\n",
    "  for word in line.split(\" \"):  \n",
    "    yield (word, 1)\n",
    " \n",
    "def REDUCE(word:str, counts:Iterator[int]):\n",
    "  sum = 0\n",
    "  for c in counts:\n",
    "    sum += c\n",
    "  yield (word, sum)\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "output = list(output)\n",
    "output"
   ],
   "execution_count": 228,
   "outputs": [
    {
     "data": {
      "text/plain": "[('', 3), ('it', 9), ('is', 9), ('what', 5), ('a', 1), ('banana', 1)]"
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-jRAcYCAkkk"
   },
   "source": [
    "# MapReduce Distributed\n",
    "\n",
    "Добавляется в модель фабрика RECORDREARER-ов --- INPUTFORMAT, функция распределения промежуточных результатов по партициям PARTITIONER, и функция COMBINER для частичной аггрегации промежуточных результатов до распределения по новым партициям."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nw-b-xJsApgW",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.050210Z",
     "start_time": "2024-04-08T14:20:38.900479700Z"
    }
   },
   "source": [
    "def flatten(nested_iterable):\n",
    "  for iterable in nested_iterable:\n",
    "    for element in iterable:\n",
    "      yield element\n",
    "\n",
    "def groupbykey(iterable):\n",
    "  t = {}\n",
    "  for (k2, v2) in iterable:\n",
    "    t[k2] = t.get(k2, []) + [v2]\n",
    "  return t.items()\n",
    "      \n",
    "def groupbykey_distributed(map_partitions, PARTITIONER):\n",
    "  global reducers\n",
    "  partitions = [dict() for _ in range(reducers)]\n",
    "  for map_partition in map_partitions:\n",
    "    for (k2, v2) in map_partition:\n",
    "      p = partitions[PARTITIONER(k2)]\n",
    "      p[k2] = p.get(k2, []) + [v2]\n",
    "  return [(partition_id, sorted(partition.items(), key=lambda x: x[0])) for (partition_id, partition) in enumerate(partitions)]\n",
    " \n",
    "def PARTITIONER(obj):\n",
    "  global reducers\n",
    "  return hash(obj) % reducers\n",
    "  \n",
    "def MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, PARTITIONER=PARTITIONER, COMBINER=None):\n",
    "  map_partitions = map(lambda record_reader: flatten(map(lambda k1v1: MAP(*k1v1), record_reader)), INPUTFORMAT())\n",
    "  if COMBINER != None:\n",
    "    map_partitions = map(lambda map_partition: flatten(map(lambda k2v2: COMBINER(*k2v2), groupbykey(map_partition))), map_partitions)\n",
    "  reduce_partitions = groupbykey_distributed(map_partitions, PARTITIONER) # shuffle\n",
    "  reduce_outputs = map(lambda reduce_partition: (reduce_partition[0], flatten(map(lambda reduce_input_group: REDUCE(*reduce_input_group), reduce_partition[1]))), reduce_partitions)\n",
    "  \n",
    "  print(\"{} key-value pairs were sent over a network.\".format(sum([len(vs) for (k,vs) in flatten([partition for (partition_id, partition) in reduce_partitions])])))\n",
    "  return reduce_outputs"
   ],
   "execution_count": 229,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxirlf3XqZxY"
   },
   "source": [
    "## Спецификация MapReduce Distributed\n",
    "\n",
    "\n",
    "```\n",
    "f (k1, v1) -> (k2,v2)*\n",
    "g (k2, v2*) -> (k3,v3)*\n",
    " \n",
    "e1 (k1, v1)\n",
    "e2 (k2, v2)\n",
    "partition1 (k2, v2)*\n",
    "partition2 (k2, v2*)*\n",
    " \n",
    "flatmap (e1->e2*, e1*) -> partition1*\n",
    "groupby (partition1*) -> partition2*\n",
    "\n",
    "mapreduce ((k1,v1)*) -> (k3,v3)*\n",
    "mapreduce .flatmap(f).groupby(k2).flatmap(g)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWYw_CpbbY3C"
   },
   "source": [
    "## WordCount "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uR_zfGFkMZlp",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "outputId": "c8d46167-473d-43b9-881a-2396991b3731",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.050210Z",
     "start_time": "2024-04-08T14:20:38.915989800Z"
    }
   },
   "source": [
    "from typing import Iterator\n",
    "import numpy as np\n",
    "\n",
    "d1 = \"\"\"\n",
    "it is what it is\n",
    "it is what it is\n",
    "it is what it is\"\"\"\n",
    "d2 = \"\"\"\n",
    "what is it\n",
    "what is it\"\"\"\n",
    "d3 = \"\"\"\n",
    "it is a banana\"\"\"\n",
    "documents = [d1, d2, d3, d1, d2, d3]\n",
    "\n",
    "maps = 3\n",
    "reducers = 2\n",
    "\n",
    "def INPUTFORMAT():\n",
    "  global maps\n",
    "  \n",
    "  def RECORDREADER(split):\n",
    "    for (docid, document) in enumerate(split):\n",
    "      for (lineid, line) in enumerate(document.split('\\n')):\n",
    "        yield (\"{}:{}\".format(docid,lineid), line)\n",
    "      \n",
    "  split_size =  int(np.ceil(len(documents)/maps))\n",
    "  for i in range(0, len(documents), split_size):\n",
    "    yield RECORDREADER(documents[i:i+split_size])\n",
    "\n",
    "def MAP(docId:str, line:str):\n",
    "  for word in line.split(\" \"):  \n",
    "    yield (word, 1)\n",
    " \n",
    "def REDUCE(word:str, counts:Iterator[int]):\n",
    "  sum = 0\n",
    "  for c in counts:\n",
    "    sum += c\n",
    "  yield (word, sum)\n",
    "  \n",
    "# try to set COMBINER=REDUCER and look at the number of values sent over the network \n",
    "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, COMBINER=None) \n",
    "partitioned_output = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
    "partitioned_output"
   ],
   "execution_count": 230,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 key-value pairs were sent over a network.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[(0, [('', 6), ('a', 2), ('banana', 2), ('it', 18)]),\n (1, [('is', 18), ('what', 10)])]"
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCJGx8IQ87xS"
   },
   "source": [
    "## TeraSort"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P2v8v1v_8_YR",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "outputId": "e0987c25-9757-46cb-8e55-d5d2adfbee2b",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.069726300Z",
     "start_time": "2024-04-08T14:20:38.929504800Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "input_values = np.random.rand(30)\n",
    "maps = 3\n",
    "reducers = 2\n",
    "min_value = 0.0\n",
    "max_value = 1.0\n",
    "\n",
    "def INPUTFORMAT():\n",
    "  global maps\n",
    "  \n",
    "  def RECORDREADER(split):\n",
    "    for value in split:\n",
    "        yield (value, None)\n",
    "      \n",
    "  split_size =  int(np.ceil(len(input_values)/maps))\n",
    "  for i in range(0, len(input_values), split_size):\n",
    "    yield RECORDREADER(input_values[i:i+split_size])\n",
    "    \n",
    "def MAP(value:int, _):\n",
    "  yield (value, None)\n",
    "  \n",
    "def PARTITIONER(key):\n",
    "  global reducers\n",
    "  global max_value\n",
    "  global min_value\n",
    "  bucket_size = (max_value-min_value)/reducers\n",
    "  bucket_id = 0\n",
    "  while((key>(bucket_id+1)*bucket_size) and ((bucket_id+1)*bucket_size<max_value)):\n",
    "    bucket_id += 1\n",
    "  return bucket_id\n",
    "\n",
    "def REDUCE(value:int, _):\n",
    "  yield (None,value)\n",
    "  \n",
    "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, COMBINER=None, PARTITIONER=PARTITIONER)\n",
    "partitioned_output = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
    "partitioned_output"
   ],
   "execution_count": 231,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 key-value pairs were sent over a network.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[(0,\n  [(None, 0.02864986366543376),\n   (None, 0.03915008333828651),\n   (None, 0.05100790444317893),\n   (None, 0.10137151779218667),\n   (None, 0.10949087373136146),\n   (None, 0.2418379970174902),\n   (None, 0.2582099736711718),\n   (None, 0.2716784104017891),\n   (None, 0.2957814180435243),\n   (None, 0.3077480290527732),\n   (None, 0.36714985134319955),\n   (None, 0.43361765926454376),\n   (None, 0.43767000424729086),\n   (None, 0.45301443224637616),\n   (None, 0.4780750968058636),\n   (None, 0.49556361452821773)]),\n (1,\n  [(None, 0.5262876475542675),\n   (None, 0.5280682289449264),\n   (None, 0.6401131511619635),\n   (None, 0.6891958623659773),\n   (None, 0.7080477973445839),\n   (None, 0.7614958241288134),\n   (None, 0.8095261291710496),\n   (None, 0.8232460879874129),\n   (None, 0.8945010257548972),\n   (None, 0.9341595436974924),\n   (None, 0.9898492416034287),\n   (None, 0.9924338247268286),\n   (None, 0.9961520307599907),\n   (None, 0.9966812014696435)])]"
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iy65YJTH99iT"
   },
   "source": [
    "# Упражнения\n",
    "Упражнения взяты из Rajaraman A., Ullman J. D. Mining of massive datasets. – Cambridge University Press, 2011.\n",
    "\n",
    "\n",
    "Для выполнения заданий переопределите функции RECORDREADER, MAP, REDUCE. Для модели распределённой системы может потребоваться переопределение функций PARTITION и COMBINER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfvAeZm3S8S8"
   },
   "source": [
    "### Максимальное значение ряда\n",
    "\n",
    "Разработайте MapReduce алгоритм, который находит максимальное число входного списка чисел."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3GRA1JR-Tkbg",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.072729700Z",
     "start_time": "2024-04-08T14:20:38.945526200Z"
    }
   },
   "source": [
    "# Имитация входных данных\n",
    "input_numbers = [3, 41, 52, 26, 38, 57, 9, 49]\n",
    "\n",
    "# RECORDREADER\n",
    "def RECORDREADER():\n",
    "    for index, value in enumerate(input_numbers):\n",
    "        yield (index, value)\n",
    "\n",
    "# MAP функция\n",
    "def MAP(_, value):\n",
    "    yield (None, value)  # Используем None как ключ, так как нам не важна группировка по ключу\n",
    "\n",
    "# REDUCE функция\n",
    "def REDUCE(_, values: Iterator):\n",
    "    max_value = max(values)  # Находим максимум среди всех значений\n",
    "    yield (None, max_value)\n",
    "\n",
    "# Исполнение MapReduce\n",
    "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
    "    map_output = flatten(map(lambda x: MAP(*x), RECORDREADER()))\n",
    "    shuffle_output = groupbykey(map_output)\n",
    "    reduce_output = flatten(map(lambda x: REDUCE(*x), shuffle_output))\n",
    "    return list(reduce_output)\n",
    "\n",
    "# Выполнение MapReduce алгоритма\n",
    "max_value_output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "print(max_value_output)"
   ],
   "execution_count": 232,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 57)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k86bXnqZTk-U"
   },
   "source": [
    "### Арифметическое среднее\n",
    "\n",
    "Разработайте MapReduce алгоритм, который находит арифметическое среднее.\n",
    "\n",
    "$$\\overline{X} = \\frac{1}{n}\\sum_{i=0}^{n} x_i$$\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MPoY5pkfUNZf",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.072729700Z",
     "start_time": "2024-04-08T14:20:39.008664700Z"
    }
   },
   "source": [
    "input_numbers = [10, 20, 30, 40, 50]\n",
    "\n",
    "# RECORDREADER\n",
    "def RECORDREADER():\n",
    "    for index, value in enumerate(input_numbers):\n",
    "        yield (index, value)\n",
    "\n",
    "# MAP функция\n",
    "def MAP(_, value):\n",
    "    yield (None, value)  # Используем None как ключ, так как нам не важно разделение на группы\n",
    "\n",
    "# REDUCE функция\n",
    "def REDUCE(_, values: Iterator):\n",
    "    total_sum = 0\n",
    "    count = 0\n",
    "    for value in values:\n",
    "        total_sum += value\n",
    "        count += 1\n",
    "    average = total_sum / count  # Вычисляем среднее значение\n",
    "    yield (None, average)\n",
    "\n",
    "# Выполнение MapReduce\n",
    "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
    "    map_output = flatten(map(lambda x: MAP(*x), RECORDREADER()))\n",
    "    shuffle_output = groupbykey(map_output)\n",
    "    reduce_output = flatten(map(lambda x: REDUCE(*x), shuffle_output))\n",
    "    return list(reduce_output)\n",
    "\n",
    "# Выполнение MapReduce алгоритма для вычисления среднего\n",
    "average_output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "print(average_output)"
   ],
   "execution_count": 233,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 30.0)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xanzszhsIlLe"
   },
   "source": [
    "### GroupByKey на основе сортировки\n",
    "\n",
    "Реализуйте groupByKey на основе сортировки, проверьте его работу на примерах"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hQPn3USsIkEC",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.073729600Z",
     "start_time": "2024-04-08T14:20:39.026684700Z"
    }
   },
   "source": [
    "import random\n",
    "from itertools import chain\n",
    "\n",
    "# Функция для выравнивания списка списков\n",
    "def flatten(lst):\n",
    "    return list(chain.from_iterable(lst))\n",
    "\n",
    "# Функция MAP, которая возвращает пару (ключ, значение)\n",
    "def MAP(input_data):\n",
    "    return (1, input_data)\n",
    "\n",
    "# Функция для группировки по ключу\n",
    "def groupbykey(items):\n",
    "    sorted_items = sorted(items, key=lambda x: x[0])\n",
    "    grouped = {}\n",
    "    for key, value in sorted_items:\n",
    "        if key in grouped:\n",
    "            grouped[key].append(value)\n",
    "        else:\n",
    "            grouped[key] = [value]\n",
    "    return [(k, list(v)) for k, v in grouped.items()]\n",
    "\n",
    "# Функция REDUCE, вычисляющая среднее значение\n",
    "def REDUCE(key, values):\n",
    "    total_sum = 0\n",
    "    total_count = 0\n",
    "    for value in values:\n",
    "        total_sum += value\n",
    "        total_count += 1\n",
    "    average = total_sum / total_count if total_count > 0 else 0\n",
    "    return average\n",
    "\n",
    "# Функция, имитирующая чтение записей (в данном случае генерирует случайные числа)\n",
    "def RECORDREADER(count):\n",
    "    return [random.randint(0, 100) for i in range(count)]\n",
    "\n",
    "# Генерируем данные и применяем функцию MAP\n",
    "mapped_data = list(map(lambda x: MAP(x), RECORDREADER(10)))\n",
    "\n",
    "print(\"Mapped Data:\", mapped_data)\n",
    "\n",
    "# Группируем данные по ключу\n",
    "shuffle_output = groupbykey(mapped_data)\n",
    "\n",
    "print(\"Shuffled Data:\", shuffle_output)\n",
    "\n",
    "# Применяем функцию REDUCE\n",
    "reduce_output = list(map(lambda x: REDUCE(*x), shuffle_output))\n",
    "\n",
    "print(\"Reduce Output:\", reduce_output)"
   ],
   "execution_count": 234,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped Data: [(1, 44), (1, 29), (1, 66), (1, 67), (1, 81), (1, 40), (1, 9), (1, 67), (1, 71), (1, 47)]\n",
      "Shuffled Data: [(1, [44, 29, 66, 67, 81, 40, 9, 67, 71, 47])]\n",
      "Reduce Output: [52.1]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SgEjCZyGnu6"
   },
   "source": [
    "### Drop duplicates (set construction, unique elements, distinct)\n",
    "\n",
    "Реализуйте распределённую операцию исключения дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "okjbyApjGhMt",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.081236Z",
     "start_time": "2024-04-08T14:20:39.041707100Z"
    }
   },
   "source": [
    "def INPUTFORMAT():\n",
    "    split_size = int(np.ceil(len(documents) / maps))\n",
    "    for i in range(0, len(documents), split_size):\n",
    "        yield (\n",
    "            (docid, line)\n",
    "            for docid, document in enumerate(documents[i:i + split_size])\n",
    "            for lineid, line in enumerate(document.split('\\n'))\n",
    "        )\n",
    "\n",
    "\n",
    "def MAP(docId, line):\n",
    "    for word in line.split():\n",
    "        if word:  # Проверяем, что слово не пустое\n",
    "            yield (word, 1)\n",
    "\n",
    "\n",
    "def REDUCE(key, _):\n",
    "    yield (key, None)  # Возвращаем только ключи, исключая дубликаты\n",
    "\n",
    "\n",
    "def groupbykey_distributed(map_output, PARTITIONER):\n",
    "    partitions = [{} for _ in range(reducers)]\n",
    "    for key, value in map_output:\n",
    "        partition = PARTITIONER(key)\n",
    "        partitions[partition][key] = None  # Игнорируем значение, сохраняем только ключ\n",
    "    return [(i, partition.keys()) for i, partition in enumerate(partitions)]\n",
    "\n",
    "\n",
    "def PARTITIONER(key):\n",
    "    return hash(key) % reducers\n",
    "\n",
    "\n",
    "def MapReduceDistributed(INPUTFORMAT, MAP, REDUCE):\n",
    "    map_output = flatten([MAP(docId, line) for docId, line in flatten(INPUTFORMAT())])\n",
    "    shuffle_output = groupbykey_distributed(map_output, PARTITIONER)\n",
    "    reduce_output = [(partition_id, list(flatten(REDUCE(key, None) for key in keys))) for partition_id, keys in\n",
    "                     shuffle_output]\n",
    "    return reduce_output\n",
    "\n",
    "\n",
    "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE)\n",
    "print(partitioned_output)"
   ],
   "execution_count": 235,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, [('it', None), ('a', None), ('banana', None)]), (1, [('is', None), ('what', None)])]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7sRGoTXuJze"
   },
   "source": [
    "#Операторы реляционной алгебры\n",
    "### Selection (Выборка)\n",
    "\n",
    "**The Map Function**: Для  каждого кортежа $t \\in R$ вычисляется истинность предиката $C$. В случае истины создаётся пара ключ-значение $(t, t)$. В паре ключ и значение одинаковы, равны $t$.\n",
    "\n",
    "**The Reduce Function:** Роль функции Reduce выполняет функция идентичности, которая возвращает то же значение, что получила на вход.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4nKIKe59uIfc",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.212526100Z",
     "start_time": "2024-04-08T14:20:39.054213400Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "# Функция, генерирующая список случайных трёхмерных кортежей\n",
    "def RECORDREADER(count):\n",
    "    return [(random.randint(0, 100), random.randint(0, 100), random.randint(0, 100)) for i in range(count)]\n",
    "\n",
    "# Предикат для функции MAP\n",
    "def C(t):\n",
    "    return sum(t) > 200\n",
    "\n",
    "# Функция MAP\n",
    "def MAP(el_list):\n",
    "    mapped_result = {t: [t] for t in el_list if C(t)}\n",
    "    return mapped_result.items()\n",
    "\n",
    "# Функция REDUCE\n",
    "def REDUCE(mapped_items):\n",
    "    return [key for key, _ in mapped_items]\n",
    "\n",
    "# Генерация записей\n",
    "record = RECORDREADER(10)\n",
    "print(\"Generated records:\", record)\n",
    "\n",
    "# Разбиваем записи на части\n",
    "part_count = 5\n",
    "record_partitional = [record[i:i + part_count] for i in range(0, len(record), part_count)]\n",
    "\n",
    "# Применяем функции MAP и REDUCE\n",
    "reduced_output = REDUCE([item for sublist in map(MAP, record_partitional) for item in sublist])\n",
    "print(\"Reduced output:\", reduced_output)"
   ],
   "execution_count": 236,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated records: [(69, 47, 83), (100, 54, 12), (53, 2, 0), (82, 8, 98), (63, 94, 21), (60, 13, 24), (60, 56, 30), (38, 100, 70), (91, 85, 74), (4, 7, 61)]\n",
      "Reduced output: [(38, 100, 70), (91, 85, 74)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w27Ca-_Ku85V"
   },
   "source": [
    "### Projection (Проекция)\n",
    "\n",
    "Проекция на множество атрибутов $S$.\n",
    "\n",
    "**The Map Function:** Для каждого кортежа $t \\in R$ создайте кортеж $t′$, исключая  из $t$ те значения, атрибуты которых не принадлежат  $S$. Верните пару $(t′, t′)$.\n",
    "\n",
    "**The Reduce Function:** Для каждого ключа $t′$, созданного любой Map задачей, вы получаете одну или несколько пар $(t′, t′)$. Reduce функция преобразует $(t′, [t′, t′, . . . , t′])$ в $(t′, t′)$, так, что для ключа $t′$ возвращается одна пара  $(t′, t′)$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BEvuY4GqvhS6",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.213526600Z",
     "start_time": "2024-04-08T14:20:39.118378200Z"
    }
   },
   "source": [
    "# Определяем множество индексов для проекции\n",
    "S = {0, 2}  # Проекция на первый и третий элементы трёхмерного кортежа\n",
    "\n",
    "def MAP(t):\n",
    "    # Проекция кортежа на множество атрибутов S\n",
    "    res = tuple(t[i] for i in range(len(t)) if i in S)\n",
    "    return (res, res)\n",
    "\n",
    "def REDUCE(key, values):\n",
    "    # Возвращаем только ключ, так как значения дублируют ключ\n",
    "    return key\n",
    "\n",
    "def RECORDREADER(count):\n",
    "    # Генерация списка случайных трёхмерных кортежей\n",
    "    return [(random.randint(0, 100), random.randint(0, 100), random.randint(0, 100)) for _ in range(count)]\n",
    "\n",
    "def group_by_key(iterable):\n",
    "    grouped = {}\n",
    "    for k, v in iterable:\n",
    "        grouped.setdefault(k, []).append(v)\n",
    "    return list(grouped.items())\n",
    "\n",
    "# Генерация и обработка записей\n",
    "record = RECORDREADER(5)\n",
    "map_output = [MAP(x) for x in record]\n",
    "shuffle_output = group_by_key(map_output)\n",
    "reduce_output = [REDUCE(key, values) for key, values in shuffle_output]\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Original records:\", record)\n",
    "print(\"Map output:\", map_output)\n",
    "print(\"Shuffle (group by key) output:\", shuffle_output)\n",
    "print(\"Reduce output:\", reduce_output)\n"
   ],
   "execution_count": 237,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original records: [(9, 77, 25), (3, 79, 78), (79, 15, 15), (44, 58, 94), (50, 45, 76)]\n",
      "Map output: [((9, 25), (9, 25)), ((3, 78), (3, 78)), ((79, 15), (79, 15)), ((44, 94), (44, 94)), ((50, 76), (50, 76))]\n",
      "Shuffle (group by key) output: [((9, 25), [(9, 25)]), ((3, 78), [(3, 78)]), ((79, 15), [(79, 15)]), ((44, 94), [(44, 94)]), ((50, 76), [(50, 76)])]\n",
      "Reduce output: [(9, 25), (3, 78), (79, 15), (44, 94), (50, 76)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gau6lKXvn2R"
   },
   "source": [
    "### Union (Объединение)\n",
    "\n",
    "**The Map Function:** Превратите каждый входной кортеж $t$ в пару ключ-значение $(t, t)$.\n",
    "\n",
    "**The Reduce Function:** С каждым ключом $t$ будет ассоциировано одно или два значений. В обоих случаях создайте $(t, t)$ в качестве выходного значения."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Sns7a5agv3nw",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.213526600Z",
     "start_time": "2024-04-08T14:20:39.132394300Z"
    }
   },
   "source": [
    "import random\n",
    "from typing import List, Tuple, Iterator\n",
    "\n",
    "TupleType = Tuple[int, int, int]\n",
    "\n",
    "# Функция MAP\n",
    "def MAP(t: TupleType) -> Tuple[TupleType, TupleType]:\n",
    "    return (t, t)\n",
    "\n",
    "# Функция REDUCE\n",
    "def REDUCE(key: TupleType, values: Iterator[TupleType]) -> Tuple[TupleType, TupleType]:\n",
    "    return (key, key)\n",
    "\n",
    "# Функция для генерации случайных кортежей\n",
    "def RECORDREADER(count: int) -> List[TupleType]:\n",
    "    return [(random.randint(0, 100), random.randint(0, 100), random.randint(0, 100)) for _ in range(count)]\n",
    "\n",
    "# Функция для группировки по ключу\n",
    "def group_by_key(iterable: List[Tuple[TupleType, TupleType]]) -> List[Tuple[TupleType, List[TupleType]]]:\n",
    "    t = {}\n",
    "    for k2, v2 in iterable:\n",
    "        t[k2] = t.get(k2, []) + [v2]\n",
    "    return list(t.items())\n",
    "\n",
    "# Генерация и обработка данных\n",
    "record = RECORDREADER(3)\n",
    "map_output = [MAP(x) for x in record]\n",
    "\n",
    "shuffle_output = list(group_by_key(map_output))\n",
    "\n",
    "reduce_output = [REDUCE(key, values)[0] for key, values in shuffle_output]\n",
    "\n",
    "print(\"Record:\\n\", record)\n",
    "print(\"Map Output:\\n\", map_output)\n",
    "print(\"Shuffle Output:\\n\", shuffle_output)\n",
    "print(\"Reduce Output:\\n\", reduce_output)"
   ],
   "execution_count": 238,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record:\n",
      " [(6, 32, 13), (65, 96, 68), (20, 99, 78)]\n",
      "Map Output:\n",
      " [((6, 32, 13), (6, 32, 13)), ((65, 96, 68), (65, 96, 68)), ((20, 99, 78), (20, 99, 78))]\n",
      "Shuffle Output:\n",
      " [((6, 32, 13), [(6, 32, 13)]), ((65, 96, 68), [(65, 96, 68)]), ((20, 99, 78), [(20, 99, 78)])]\n",
      "Reduce Output:\n",
      " [(6, 32, 13), (65, 96, 68), (20, 99, 78)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ8TuEbjv4J8"
   },
   "source": [
    "### Intersection (Пересечение)\n",
    "\n",
    "**The Map Function:** Превратите каждый кортеж $t$ в пары ключ-значение $(t, t)$.\n",
    "\n",
    "**The Reduce Function:** Если для ключа $t$ есть список из двух элементов $[t, t]$ $-$ создайте пару $(t, t)$. Иначе, ничего не создавайте."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XKlBZh4IwERR",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.213526600Z",
     "start_time": "2024-04-08T14:20:39.150464900Z"
    }
   },
   "source": [
    "import random\n",
    "from typing import Tuple, List\n",
    "\n",
    "# Определение типа кортежа\n",
    "TupleType = Tuple[int, int]\n",
    "\n",
    "# Функция MAP\n",
    "def MAP(t: TupleType) -> Tuple[TupleType, TupleType]:\n",
    "    return (t, t)\n",
    "\n",
    "# Функция REDUCE\n",
    "def REDUCE(key: TupleType, values: List[TupleType]) -> Tuple[TupleType, TupleType]:\n",
    "    if len(values) > 1:  # Проверяем, что элемент присутствует в обоих наборах\n",
    "        return (key, key)\n",
    "\n",
    "# Функция для генерации случайных кортежей\n",
    "def RECORDREADER(count: int) -> List[TupleType]:\n",
    "    return [(random.randint(0, 3), random.randint(0, 3)) for _ in range(count)]\n",
    "\n",
    "# Функция для группировки по ключу\n",
    "def group_by_key(iterable: List[Tuple[TupleType, TupleType]]) -> List[Tuple[TupleType, List[TupleType]]]:\n",
    "    grouped = {}\n",
    "    for key, value in iterable:\n",
    "        grouped.setdefault(key, []).append(value)\n",
    "    return list(grouped.items())\n",
    "\n",
    "# Генерация двух наборов данных\n",
    "record1 = RECORDREADER(3)\n",
    "record2 = RECORDREADER(3)\n",
    "\n",
    "# Объединение записей из обоих наборов\n",
    "combined_records = record1 + record2\n",
    "\n",
    "# Применение функции MAP и группировка результатов\n",
    "map_output = [MAP(x) for x in combined_records]\n",
    "shuffle_output = list(group_by_key(map_output))\n",
    "\n",
    "# Применение функции REDUCE и фильтрация ненужных результатов\n",
    "reduce_output = [REDUCE(*item) for item in shuffle_output if len(item[1]) > 1]\n",
    "\n",
    "print(\"Record1:\\n\", record1)\n",
    "print(\"Record2:\\n\", record2)\n",
    "print(\"Reduce Output:\\n\", [item for item in reduce_output])\n"
   ],
   "execution_count": 239,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record1:\n",
      " [(0, 3), (1, 0), (0, 3)]\n",
      "Record2:\n",
      " [(3, 3), (1, 2), (3, 0)]\n",
      "Reduce Output:\n",
      " [((0, 3), (0, 3))]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVOpqoY3wE5k"
   },
   "source": [
    "### Difference (Разница)\n",
    "\n",
    "**The Map Function:** Для кортежа $t \\in R$, создайте пару $(t, R)$, и для кортежа $t \\in S$, создайте пару $(t, S)$. Задумка заключается в том, чтобы значение пары было именем отношения $R$ or $S$, которому принадлежит кортеж (а лучше, единичный бит, по которому можно два отношения различить $R$ or $S$), а не весь набор атрибутов отношения.\n",
    "\n",
    "**The Reduce Function:** Для каждого ключа $t$, если соответствующее значение является списком $[R]$, создайте пару $(t, t)$. В иных случаях не предпринимайте действий."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QE_AC09lwZIZ",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.214526900Z",
     "start_time": "2024-04-08T14:20:39.167483Z"
    }
   },
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Константы для обозначения принадлежности кортежа к множеству\n",
    "SET_R = 0\n",
    "SET_S = 1\n",
    "\n",
    "# Создание случайного элемента с указанием его принадлежности к множеству\n",
    "def create_random_element() -> Tuple[Tuple[int, int], int]:\n",
    "    element = (random.randint(1, 4), random.randint(1, 4))\n",
    "    set_indicator = random.choice([SET_R, SET_S])\n",
    "    return (element, set_indicator)\n",
    "\n",
    "# Функция чтения данных, имитирующая получение набора данных\n",
    "def fetch_data(sample_size: int) -> List[Tuple[Tuple[int, int], int]]:\n",
    "    return [create_random_element() for _ in range(sample_size)]\n",
    "\n",
    "# Функция отображения, присваивающая каждому элементу его множество\n",
    "def map_element(input_element: Tuple[Tuple[int, int], int]) -> Tuple[Tuple[int, int], int]:\n",
    "    return input_element\n",
    "\n",
    "# Функция свёртки, выбирающая элементы, принадлежащие только первому множеству\n",
    "def filter_unique(key: Tuple[int, int], belonging: List[int]) -> Tuple[Tuple[int, int], Tuple[int, int]]:\n",
    "    if belonging.count(SET_R) == 1 and SET_S not in belonging:\n",
    "        return (key, key)\n",
    "\n",
    "# Организация элементов по ключам\n",
    "def organize_by_key(elements: List[Tuple[Tuple[int, int], int]]) -> Dict[Tuple[int, int], List[int]]:\n",
    "    organization = defaultdict(list)\n",
    "    for element_key, relation in elements:\n",
    "        organization[element_key].append(relation)\n",
    "    return organization\n",
    "\n",
    "# Процесс MapReduce\n",
    "data_samples = fetch_data(5)\n",
    "mapped_samples = [map_element(sample) for sample in data_samples]\n",
    "organized_data = organize_by_key(mapped_samples)\n",
    "filtered_results = [filter_unique(k, v) for k, v in organized_data.items() if filter_unique(k, v) is not None]\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Generated Samples:\\n\", data_samples)\n",
    "print(\"Mapped Samples:\\n\", mapped_samples)\n",
    "print(\"Organized Data:\\n\", dict(organized_data))\n",
    "print(\"Filtered (Unique) Results:\\n\", filtered_results)"
   ],
   "execution_count": 240,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Samples:\n",
      " [((4, 3), 0), ((1, 3), 1), ((2, 1), 1), ((1, 3), 0), ((4, 3), 1)]\n",
      "Mapped Samples:\n",
      " [((4, 3), 0), ((1, 3), 1), ((2, 1), 1), ((1, 3), 0), ((4, 3), 1)]\n",
      "Organized Data:\n",
      " {(4, 3): [0, 1], (1, 3): [1, 0], (2, 1): [1]}\n",
      "Filtered (Unique) Results:\n",
      " []\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8I58V2VwhSm"
   },
   "source": [
    "### Natural Join\n",
    "\n",
    "**The Map Function:** Для каждого кортежа $(a, b)$ отношения $R$, создайте пару $(b,(R, a))$. Для каждого кортежа $(b, c)$ отношения $S$, создайте пару $(b,(S, c))$.\n",
    "\n",
    "**The Reduce Function:** Каждый ключ $b$ будет асоциирован со списком пар, которые принимают форму либо $(R, a)$, либо $(S, c)$. Создайте все пары, одни, состоящие из  первого компонента $R$, а другие, из первого компонента $S$, то есть $(R, a)$ и $(S, c)$. На выходе вы получаете последовательность пар ключ-значение из списков ключей и значений. Ключ не нужен. Каждое значение, это тройка $(a, b, c)$ такая, что $(R, a)$ и $(S, c)$ это принадлежат входному списку значений."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yHiuuTctw86I",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.215526500Z",
     "start_time": "2024-04-08T14:20:39.180007100Z"
    }
   },
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Iterable\n",
    "\n",
    "# Идентификаторы для отношений R и S\n",
    "REL_R = 'R'\n",
    "REL_S = 'S'\n",
    "\n",
    "# Генерация случайного кортежа для отношений R и S\n",
    "def generate_random_tuple(is_relation_r: bool) -> Tuple[Tuple[int, int], str]:\n",
    "    values = (random.randint(0, 3), random.randint(0, 3))\n",
    "    relation = REL_R if is_relation_r else REL_S\n",
    "    return (values, relation)\n",
    "\n",
    "# Чтение записей, аналогичное RECORDREADER\n",
    "def fetch_records(total: int) -> List[Tuple[Tuple[int, int], str]]:\n",
    "    return [generate_random_tuple(i < total // 2) for i in range(total)]\n",
    "\n",
    "# MAP функция, трансформирующая входные данные\n",
    "def MAP(record: Tuple[Tuple[int, int], str]) -> Tuple[int, Tuple[str, int]]:\n",
    "    ((a, b), relation) = record\n",
    "    return (b, (relation, a)) if relation == REL_R else (a, (relation, b))\n",
    "\n",
    "# REDUCE функция, обрабатывающая сгруппированные данные\n",
    "def REDUCE(key: int, grouped_values: Iterable[Tuple[str, int]]) -> List[Tuple[int, int, int]]:\n",
    "    r_values = [value for relation, value in grouped_values if relation == REL_R]\n",
    "    s_values = [value for relation, value in grouped_values if relation == REL_S]\n",
    "    return [(r, key, s) for r in r_values for s in s_values]\n",
    "\n",
    "# Группировка по ключу, аналогичная group_by_key\n",
    "def group_by_key(mapped: List[Tuple[int, Tuple[str, int]]]) -> Dict[int, List[Tuple[str, int]]]:\n",
    "    grouped = defaultdict(list)\n",
    "    for key, value in mapped:\n",
    "        grouped[key].append(value)\n",
    "    return grouped\n",
    "\n",
    "# Пример использования\n",
    "data = fetch_records(7)  # Генерация случайных записей\n",
    "mapped = [MAP(item) for item in data]  # Применение MAP\n",
    "grouped = group_by_key(mapped)  # Группировка по ключу\n",
    "reduced = [result for key, values in grouped.items() for result in REDUCE(key, values)]  # Применение REDUCE\n",
    "\n",
    "print(\"Raw Data:\\n\", data)\n",
    "print(\"Mapped Data:\\n\", mapped)\n",
    "print(\"Grouped Data:\\n\", dict(grouped))\n",
    "print(\"Reduced Results:\\n\", reduced)"
   ],
   "execution_count": 241,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data:\n",
      " [((2, 1), 'R'), ((3, 0), 'R'), ((1, 3), 'R'), ((1, 2), 'S'), ((0, 3), 'S'), ((0, 0), 'S'), ((3, 3), 'S')]\n",
      "Mapped Data:\n",
      " [(1, ('R', 2)), (0, ('R', 3)), (3, ('R', 1)), (1, ('S', 2)), (0, ('S', 3)), (0, ('S', 0)), (3, ('S', 3))]\n",
      "Grouped Data:\n",
      " {1: [('R', 2), ('S', 2)], 0: [('R', 3), ('S', 3), ('S', 0)], 3: [('R', 1), ('S', 3)]}\n",
      "Reduced Results:\n",
      " [(2, 1, 2), (3, 0, 3), (3, 0, 0), (1, 3, 3)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYdlr0YUxE27"
   },
   "source": [
    "### Grouping and Aggregation (Группировка и аггрегация)\n",
    "\n",
    "**The Map Function:** Для каждого кортежа $(a, b, c$) создайте пару $(a, b)$.\n",
    "\n",
    "**The Reduce Function:** Ключ представляет ту или иную группу. Примение аггрегирующую операцию $\\theta$ к списку значений $[b1, b2, . . . , bn]$ ассоциированных с ключом $a$. Возвращайте в выходной поток $(a, x)$, где $x$ результат применения  $\\theta$ к списку. Например, если $\\theta$ это $SUM$, тогда $x = b1 + b2 + · · · + bn$, а если $\\theta$ is $MAX$, тогда $x$ это максимальное из значений $b1, b2, . . . , bn$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum Reduce Output:\n",
      "[(2, 9), (0, 4), (1, 5)]\n",
      "Max Reduce Output:\n",
      "[(2, 3), (0, 3), (1, 3)]\n",
      "Min Reduce Output:\n",
      "[(2, 2), (0, 0), (1, 2)]\n",
      "Avg Reduce Output:\n",
      "[(2, 2.25), (0, 1.0), (1, 2.5)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import List, Tuple, Dict, Callable\n",
    "\n",
    "# Генерация случайного трехэлементного кортежа\n",
    "def get_random_tuple() -> Tuple[int, int, int]:\n",
    "    return (random.randint(0, 3), random.randint(0, 3), random.randint(0, 3))\n",
    "\n",
    "# Имитация чтения данных, генерируя список случайных кортежей\n",
    "def RECORDREADER(count: int) -> List[Tuple[int, int, int]]:\n",
    "    return [get_random_tuple() for _ in range(count)]\n",
    "\n",
    "# Функция MAP, которая преобразует входные кортежи\n",
    "def MAP(t: Tuple[int, int, int]) -> Tuple[int, int]:\n",
    "    return (t[0], t[1])\n",
    "\n",
    "# Агрегирующая функция\n",
    "def theta_aggregate(values: List[int], mode: str) -> int:\n",
    "    if mode == 'sum':\n",
    "        return sum(values)\n",
    "    elif mode == 'max':\n",
    "        return max(values)\n",
    "    elif mode == 'min':\n",
    "        return min(values)\n",
    "    elif mode == 'avg':\n",
    "        return sum(values) / len(values) if values else 0\n",
    "\n",
    "# Функция REDUCE\n",
    "def REDUCE(key: int, values: List[int], operation: str) -> Tuple[int, int]:\n",
    "    return (key, theta_aggregate(values, operation))\n",
    "\n",
    "# Группировка элементов по ключу\n",
    "def group_by_key(iterable: List[Tuple[int, int]]) -> Dict[int, List[int]]:\n",
    "    grouped = {}\n",
    "    for key, value in iterable:\n",
    "        if key not in grouped:\n",
    "            grouped[key] = [value]\n",
    "        else:\n",
    "            grouped[key].append(value)\n",
    "    return grouped\n",
    "\n",
    "# Обработка записей\n",
    "record = RECORDREADER(10)\n",
    "map_output = [MAP(x) for x in record]\n",
    "grouped_output = group_by_key(map_output)\n",
    "\n",
    "# Выполнение агрегации\n",
    "aggregations = ['sum', 'max', 'min', 'avg']\n",
    "for agg in aggregations:\n",
    "    reduce_output = [REDUCE(key, values, agg) for key, values in grouped_output.items()]\n",
    "    print(f\"{agg.capitalize()} Reduce Output:\\n{reduce_output}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.313479Z",
     "start_time": "2024-04-08T14:20:39.197015Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIrRgvG4RIS4"
   },
   "source": [
    "### Matrix-Vector multiplication\n",
    "\n",
    "Случай, когда вектор не помещается в памяти Map задачи\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIo2t7nNxvA9"
   },
   "source": [
    "## Matrix multiplication (Перемножение матриц)\n",
    "\n",
    "Если у нас есть матрица $M$ с элементами $m_{ij}$ в строке $i$ и столбце $j$, и матрица $N$ с элементами $n_{jk}$ в строке $j$ и столбце $k$, тогда их произведение $P = MN$ есть матрица $P$ с элементами $p_{ik}$ в строке $i$ и столбце $k$, где\n",
    "\n",
    "$$p_{ik} =\\sum_{j} m_{ij}n_{jk}$$\n",
    "\n",
    "Необходимым требованием является одинаковое количество столбцов в $M$ и строк в $N$, чтобы операция суммирования по  $j$ была осмысленной. Мы можем размышлять о матрице, как об отношении с тремя атрибутами: номер строки, номер столбца, само значение. Таким образом матрица $M$ предстваляется как отношение $ M(I, J, V )$, с кортежами $(i, j, m_{ij})$, и, аналогично, матрица $N$ представляется как отношение $N(J, K, W)$, с кортежами $(j, k, n_{jk})$. Так как большие матрицы как правило разреженные (большинство значений равно 0), и так как мы можем нулевыми значениями пренебречь (не хранить), такое реляционное представление достаточно эффективно для больших матриц. Однако, возможно, что координаты $i$, $j$, и $k$ неявно закодированы в смещение позиции элемента относительно начала файла, вместо явного хранения. Тогда, функция Map (или Reader) должна быть разработана таким образом, чтобы реконструировать компоненты $I$, $J$, и $K$ кортежей из смещения.\n",
    "\n",
    "Произведение $MN$ это фактически join, за которым следуют группировка по ключу и аггрегация. Таким образом join отношений $M(I, J, V )$ и $N(J, K, W)$, имеющих общим только атрибут $J$, создаст кортежи $(i, j, k, v, w)$ из каждого кортежа $(i, j, v) \\in M$ и кортежа $(j, k, w) \\in N$. Такой 5 компонентный кортеж представляет пару элементов матрицы $(m_{ij} , n_{jk})$. Что нам хотелось бы получить на самом деле, это произведение этих элементов, то есть, 4 компонентный кортеж$(i, j, k, v \\times w)$, так как он представляет произведение $m_{ij}n_{jk}$. Мы представляем отношение как результат одной MapReduce операции, в которой мы можем произвести группировку и аггрегацию, с $I$ и $K$  атрибутами, по которым идёт группировка, и суммой  $V \\times W$. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1MBkGaLAYVCt",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.313479Z",
     "start_time": "2024-04-08T14:20:39.273920700Z"
    }
   },
   "source": [
    "# MapReduce model\n",
    "def flatten(nested_iterable):\n",
    "    for iterable in nested_iterable:\n",
    "        for element in iterable:\n",
    "            yield element\n",
    "\n",
    "\n",
    "def groupbykey(iterable):\n",
    "    t = {}\n",
    "    for (k2, v2) in iterable:\n",
    "        t[k2] = t.get(k2, []) + [v2]\n",
    "    return t.items()\n",
    "\n",
    "\n",
    "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
    "    return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER())))))"
   ],
   "execution_count": 243,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMspsOT0ZB35"
   },
   "source": [
    "Реализуйте перемножение матриц с использованием модельного кода MapReduce для одной машины в случае, когда одна матрица хранится в памяти, а другая генерируется RECORDREADER-ом."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "psP1XekbsEjS",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.315477200Z",
     "start_time": "2024-04-08T14:20:39.290938300Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "I = 2\n",
    "J = 3\n",
    "K = 4 * 10\n",
    "small_mat = np.random.rand(I, J)  # it is legal to access this from RECORDREADER, MAP, REDUCE\n",
    "big_mat = np.random.rand(J, K)\n",
    "\n",
    "\n",
    "def RECORDREADER():\n",
    "    for j in range(big_mat.shape[0]):\n",
    "        for k in range(big_mat.shape[1]):\n",
    "            yield ((j, k), big_mat[j, k])\n",
    "\n",
    "\n",
    "def MAP(k1, v1):\n",
    "    (j, k) = k1\n",
    "    w = v1\n",
    "    for i in range(small_mat.shape[0]):\n",
    "        yield ((i, k), small_mat[i, j] * w)\n",
    "\n",
    "\n",
    "def REDUCE(key, values):\n",
    "    (i, k) = key\n",
    "    result = sum(values)\n",
    "    yield ((i, k), result)"
   ],
   "execution_count": 244,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnt306LHhHrm"
   },
   "source": [
    "Проверьте своё решение"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ewy_ZNYqW5a2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "9ce264f2-9412-44e2-9b0a-cc780573ab3a",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.325991200Z",
     "start_time": "2024-04-08T14:20:39.305428900Z"
    }
   },
   "source": [
    "# CHECK THE SOLUTION\n",
    "reference_solution = np.matmul(small_mat, big_mat) \n",
    "solution = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "\n",
    "def asmatrix(reduce_output):\n",
    "  reduce_output = list(reduce_output)\n",
    "  I = max(i for ((i,k), vw) in reduce_output)+1\n",
    "  K = max(k for ((i,k), vw) in reduce_output)+1\n",
    "  mat = np.empty(shape=(I,K))\n",
    "  for ((i,k), vw) in reduce_output:\n",
    "    mat[i,k] = vw\n",
    "  return mat\n",
    "\n",
    "np.allclose(reference_solution, asmatrix(solution)) # should return true"
   ],
   "execution_count": 245,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TK7v4CEcfxqf",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "2c865d0a-4065-4e6b-c83f-5508ed5eb4fa",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.382582200Z",
     "start_time": "2024-04-08T14:20:39.320996300Z"
    }
   },
   "source": [
    "reduce_output = list(MapReduce(RECORDREADER, MAP, REDUCE))\n",
    "max(i for ((i,k), vw) in reduce_output)"
   ],
   "execution_count": 246,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4yyg3kOZqJJ"
   },
   "source": [
    "Реализуйте перемножение матриц  с использованием модельного кода MapReduce для одной машины в случае, когда обе матрицы генерируются в RECORDREADER. Например, сначала одна, а потом другая."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3B7rIAJCaHZq",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.399603900Z",
     "start_time": "2024-04-08T14:20:39.338500400Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "I = 2\n",
    "J = 3\n",
    "K = 4*10\n",
    "small_mat = np.random.rand(I,J)\n",
    "big_mat = np.random.rand(J,K)\n",
    "reference_solution = np.matmul(small_mat, big_mat)\n",
    "\n",
    "def RECORDREADER():\n",
    "    yield from (((0, i, j), value) for i, row in enumerate(small_mat) for j, value in enumerate(row))\n",
    "    yield from (((1, j, k), value) for j, row in enumerate(big_mat) for k, value in enumerate(row))\n",
    "\n",
    "\n",
    "def MAP_JOIN(k1, v1):\n",
    "    mat_num, i, j = k1\n",
    "    key = j if mat_num == 0 else i\n",
    "    yield (key, (mat_num, i if mat_num == 0 else j, v1))\n",
    "\n",
    "\n",
    "def REDUCE_JOIN(key, values):\n",
    "    for v1 in values:\n",
    "        if v1[0] == 0:\n",
    "            for v2 in values:\n",
    "                if v2[0] == 1:\n",
    "                    yield ((v1[1], v2[1]), v1[2] * v2[2])\n",
    "\n",
    "def MAP_MUL(k1, v1):\n",
    "    yield k1, v1\n",
    "\n",
    "\n",
    "def REDUCE_MUL(key, values):\n",
    "    yield (key, sum(values))\n",
    "\n",
    "\n",
    "def GET_JOINED():\n",
    "    yield from joined\n",
    "\n",
    "joined = MapReduce(RECORDREADER, MAP_JOIN, REDUCE_JOIN)\n",
    "solution = MapReduce(GET_JOINED, MAP_MUL, REDUCE_MUL)\n",
    "np.allclose(reference_solution, asmatrix(solution)) "
   ],
   "execution_count": 247,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXyzQi1DaIwo"
   },
   "source": [
    "Реализуйте перемножение матриц с использованием модельного кода MapReduce Distributed, когда каждая матрица генерируется в своём RECORDREADER. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TDM_s78Rb5eR",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.444481300Z",
     "start_time": "2024-04-08T14:20:39.408609600Z"
    }
   },
   "source": [
    "def flatten(nested_iterable):\n",
    "    for iterable in nested_iterable:\n",
    "        for element in iterable:\n",
    "            yield element\n",
    "\n",
    "\n",
    "def groupbykey(iterable):\n",
    "    t = {}\n",
    "    for (k2, v2) in iterable:\n",
    "        t[k2] = t.get(k2, []) + [v2]\n",
    "    return t.items()\n",
    "\n",
    "\n",
    "def groupbykey_distributed(map_partitions, PARTITIONER):\n",
    "    global reducers\n",
    "    partitions = [dict() for _ in range(reducers)]\n",
    "    for map_partition in map_partitions:\n",
    "        for (k2, v2) in map_partition:\n",
    "            p = partitions[PARTITIONER(k2)]\n",
    "            p[k2] = p.get(k2, []) + [v2]\n",
    "    return [(partition_id, sorted(partition.items(), key=lambda x: x[0])) for (partition_id, partition) in\n",
    "            enumerate(partitions)]\n",
    "\n",
    "\n",
    "def PARTITIONER(obj):\n",
    "    global reducers\n",
    "    return hash(obj) % reducers\n",
    "\n",
    "\n",
    "def MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, PARTITIONER=PARTITIONER, COMBINER=None):\n",
    "    map_partitions = map(lambda record_reader: flatten(map(lambda k1v1: MAP(*k1v1), record_reader)), INPUTFORMAT())\n",
    "    if COMBINER != None:\n",
    "        map_partitions = map(\n",
    "            lambda map_partition: flatten(map(lambda k2v2: COMBINER(*k2v2), groupbykey(map_partition))), map_partitions)\n",
    "    reduce_partitions = groupbykey_distributed(map_partitions, PARTITIONER)  # shuffle\n",
    "    reduce_outputs = map(lambda reduce_partition: (\n",
    "    reduce_partition[0], flatten(map(lambda reduce_input_group: REDUCE(*reduce_input_group), reduce_partition[1]))),\n",
    "                         reduce_partitions)\n",
    "\n",
    "    print(\"{} key-value pairs were sent over a network.\".format(\n",
    "        sum([len(vs) for (k, vs) in flatten([partition for (partition_id, partition) in reduce_partitions])])))\n",
    "    return reduce_outputs\n",
    "\n",
    "\n",
    "I = 3\n",
    "J = 4\n",
    "K = 4 * 10\n",
    "small_mat = np.random.rand(I, J)\n",
    "big_mat = np.random.rand(J, K)\n",
    "reference_solution = np.matmul(small_mat, big_mat)\n",
    "\n",
    "\n",
    "def INPUTFORMAT():\n",
    "    first_mat = [((0, i, j), value) for i, row in enumerate(small_mat) for j, value in enumerate(row)]\n",
    "    second_mat = [((1, j, k), value) for j, row in enumerate(big_mat) for k, value in enumerate(row)]\n",
    "    return [first_mat, second_mat]\n",
    "\n",
    "\n",
    "def MAP_JOIN(k1, v1):\n",
    "    mat_num, i, j = k1\n",
    "    key = j if mat_num == 0 else i\n",
    "    yield (key, (mat_num, i if mat_num == 0 else j, v1))\n",
    "\n",
    "\n",
    "def REDUCE_JOIN(key, values):\n",
    "    for v1 in values:\n",
    "        if v1[0] == 0:\n",
    "            for v2 in values:\n",
    "                if v2[0] == 1:\n",
    "                    yield ((v1[1], v2[1]), v1[2] * v2[2])\n",
    "\n",
    "\n",
    "def GET_JOINED():\n",
    "    yield from (j[1] for j in joined)\n",
    "\n",
    "\n",
    "def MAP_MUL(k1, v1):  #+\n",
    "    yield k1, v1\n",
    "\n",
    "\n",
    "def REDUCE_MUL(key, values):\n",
    "    yield (key, sum(values))\n",
    "\n",
    "\n",
    "maps = 8\n",
    "reducers = 4\n",
    "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP_JOIN, REDUCE_JOIN, COMBINER=None)\n",
    "joined = list(map(lambda x: (x[0], list(x[1])), partitioned_output))\n",
    "\n",
    "mul_output = MapReduceDistributed(GET_JOINED, MAP_MUL, REDUCE_MUL, COMBINER=None)\n",
    "pre_result = list(map(lambda x: (x[0], list(x[1])), mul_output))\n",
    "\n",
    "solution = [v for p in pre_result for v in p[1]]\n",
    "\n",
    "np.allclose(reference_solution, asmatrix(solution))  # should return true"
   ],
   "execution_count": 248,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172 key-value pairs were sent over a network.\n",
      "480 key-value pairs were sent over a network.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZuSA2P9Db6UM"
   },
   "source": [
    "Обобщите предыдущее решение на случай, когда каждая матрица генерируется несколькими RECORDREADER-ами, и проверьте его работоспособность. Будет ли работать решение, если RECORDREADER-ы будут генерировать случайное подмножество элементов матрицы?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ehN0FqRDcwU5",
    "ExecuteTime": {
     "end_time": "2024-04-08T14:20:39.461503900Z",
     "start_time": "2024-04-08T14:20:39.422628400Z"
    }
   },
   "source": [
    "def flatten(nested_iterable):\n",
    "  # Генератор для раскрытия вложенной структуры данных\n",
    "  for iterable in nested_iterable:\n",
    "    for element in iterable:\n",
    "      yield element\n",
    "\n",
    "def groupbykey(iterable):\n",
    "  # Группировка по ключу для итерируемой последовательности\n",
    "  t = {}\n",
    "  for (k2, v2) in iterable:\n",
    "    t[k2] = t.get(k2, []) + [v2]\n",
    "  return t.items()\n",
    "\n",
    "def groupbykey_distributed(map_partitions, PARTITIONER):\n",
    "  # Распределенная группировка по ключу\n",
    "  global reducers\n",
    "  partitions = [dict() for _ in range(reducers)]\n",
    "  for map_partition in map_partitions:\n",
    "    for (k2, v2) in map_partition:\n",
    "      p = partitions[PARTITIONER(k2)]\n",
    "      p[k2] = p.get(k2, []) + [v2]\n",
    "  return [(partition_id, sorted(partition.items(), key=lambda x: x[0])) for (partition_id, partition) in enumerate(partitions)]\n",
    "\n",
    "def PARTITIONER(obj):\n",
    "  # Функция для вычисления партиций с использованием хеш-функции\n",
    "  global reducers\n",
    "  return hash(obj) % reducers\n",
    "\n",
    "def MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, PARTITIONER=PARTITIONER, COMBINER=None):\n",
    "  # Функция для выполнения распределенной обработки MapReduce\n",
    "  map_partitions = map(lambda record_reader: flatten(map(lambda k1v1: MAP(*k1v1), record_reader)), INPUTFORMAT())\n",
    "  if COMBINER != None:\n",
    "    map_partitions = map(lambda map_partition: flatten(map(lambda k2v2: COMBINER(*k2v2), groupbykey(map_partition))), map_partitions)\n",
    "  reduce_partitions = groupbykey_distributed(map_partitions, PARTITIONER) # shuffle\n",
    "  reduce_outputs = map(lambda reduce_partition: (reduce_partition[0], flatten(map(lambda reduce_input_group: REDUCE(*reduce_input_group), reduce_partition[1]))), reduce_partitions)\n",
    "\n",
    "  print(\"{} пар ключ-значение было отправлено по сети.\".format(sum([len(vs) for (k,vs) in flatten([partition for (partition_id, partition) in reduce_partitions])])))\n",
    "  return reduce_outputs\n",
    "\n",
    "\n",
    "I = 2\n",
    "J = 3\n",
    "K = 4*10\n",
    "small_mat = np.random.rand(I,J)\n",
    "big_mat = np.random.rand(J,K)\n",
    "reference_solution = np.matmul(small_mat, big_mat)\n",
    "\n",
    "def INPUTFORMAT():\n",
    "  # Функция для форматирования входных данных в MapReduce\n",
    "  first_mat = [((0, i, j), small_mat[i,j]) for i in range(small_mat.shape[0]) for j in range(small_mat.shape[1])]\n",
    "\n",
    "  second_mat = [((1, j, k), big_mat[j,k]) for j in range(big_mat.shape[0]) for k in range(big_mat.shape[1])]\n",
    "\n",
    "  # Разбиваем первую матрицу на части\n",
    "  split_size = int(np.ceil(len(first_mat)/maps))\n",
    "  for i in range(0, len(first_mat), split_size):\n",
    "    yield first_mat[i:i+split_size]\n",
    "\n",
    "  # Разбиваем вторую матрицу на части\n",
    "  split_size = int(np.ceil(len(second_mat)/maps))\n",
    "  for i in range(0, len(second_mat), split_size):\n",
    "    yield second_mat[i:i+split_size]\n",
    "\n",
    "def MAP_JOIN(k1, v1):\n",
    "    # MAP-функция для присоединения (join) данных\n",
    "    mat_num, i, j = k1\n",
    "    key = j if mat_num == 0 else i\n",
    "    yield (key, (mat_num, i if mat_num == 0 else j, v1))\n",
    "\n",
    "def REDUCE_JOIN(key, values):\n",
    "    # REDUCE-функция для присоединения (join) данных\n",
    "    for v1 in values:\n",
    "        if v1[0] == 0:\n",
    "            for v2 in values:\n",
    "                if v2[0] == 1:\n",
    "                    yield ((v1[1], v2[1]), v1[2] * v2[2])\n",
    "\n",
    "def GET_JOINED():\n",
    "  # Генератор для извлечения данных после присоединения\n",
    "  yield from (j[1] for j in joined)\n",
    "\n",
    "def MAP_MUL(k1, v1): #+\n",
    "    # MAP-функция для умножения\n",
    "    yield k1, v1\n",
    "\n",
    "def REDUCE_MUL(key, values):\n",
    "    # REDUCE-функция для умножения\n",
    "    yield (key, sum(values))\n",
    "\n",
    "maps = 8\n",
    "reducers = 4\n",
    "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP_JOIN, REDUCE_JOIN, COMBINER=None)\n",
    "joined = list(map(lambda x: (x[0], list(x[1])), partitioned_output))\n",
    "\n",
    "mul_output = MapReduceDistributed(GET_JOINED, MAP_MUL, REDUCE_MUL, COMBINER=None)\n",
    "pre_result = list(map(lambda x: (x[0], list(x[1])), mul_output))\n",
    "\n",
    "solution = [v for p in pre_result for v in p[1]]\n",
    "\n",
    "np.allclose(reference_solution, asmatrix(solution)) # должен вернуть True"
   ],
   "execution_count": 249,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 пар ключ-значение было отправлено по сети.\n",
      "240 пар ключ-значение было отправлено по сети.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  }
 ]
}
